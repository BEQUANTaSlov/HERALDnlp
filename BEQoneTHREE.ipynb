{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 295 / 295 posts\n",
      "Not posting to Twitter because in admin mode\n",
      "\n",
      "*************************************************\n",
      "\n",
      "A BEQUANT.ORG Model: The top ten stocks discussed on /r/wallstreetbets along with NLP analysis:\n",
      "\n",
      "Ticker | Mentions | Bullish (%) | Neutral (%) | Bearish (%)\n",
      ":- | :- | :- | :- | :-\n",
      "$WISH | [165 mentions (29% of all mentions)] | 89 | 2 | 7\n",
      "$CLOV | [50 mentions (9% of all mentions)] | 40 | 50 | 10\n",
      "$BB | [37 mentions (6% of all mentions)] | 35 | 48 | 16\n",
      "$WKHS | [30 mentions (5% of all mentions)] | 60 | 33 | 6\n",
      "$CLNE | [17 mentions (3% of all mentions)] | 35 | 41 | 23\n",
      "$H | [15 mentions (2% of all mentions)] | 33 | 53 | 13\n",
      "$CLF | [14 mentions (2% of all mentions)] | 57 | 28 | 14\n",
      "$RIDE | [11 mentions (1% of all mentions)] | 45 | 45 | 9\n",
      "$AMD | [10 mentions (1% of all mentions)] | 60 | 40 | 0\n",
      "$UWMC | [9 mentions (1% of all mentions)] | 44 | 22 | 33\n",
      "$AMC | [9 mentions (1% of all mentions)] | 44 | 55 | 0\n",
      "$PLTR | [8 mentions (1% of all mentions)] | 25 | 75 | 0\n",
      "$KBH | [8 mentions (1% of all mentions)] | 50 | 25 | 25\n",
      "$PRPL | [8 mentions (1% of all mentions)] | 50 | 37 | 12\n",
      "$TLRY | [8 mentions (1% of all mentions)] | 62 | 37 | 0\n",
      "$DKNG | [8 mentions (1% of all mentions)] | 37 | 62 | 0\n",
      "$SNDL | [6 mentions (1% of all mentions)] | 50 | 50 | 0\n",
      "$BIG | [6 mentions (1% of all mentions)] | 83 | 16 | 0\n",
      "$CRSR | [5 mentions (<1% of all mentions)] | 80 | 20 | 0\n",
      "$SPY | [4 mentions (<1% of all mentions)] | 25 | 25 | 50\n",
      "$PSFE | [4 mentions (<1% of all mentions)] | 100 | 0 | 0\n",
      "$GSAT | [4 mentions (<1% of all mentions)] | 100 | 0 | 0\n",
      "$ASO | [4 mentions (<1% of all mentions)] | 75 | 25 | 0\n",
      "$COIN | [4 mentions (<1% of all mentions)] | 50 | 25 | 25\n",
      "$SKLZ | [4 mentions (<1% of all mentions)] | 25 | 75 | 0\n",
      "$RKT | [3 mentions (<1% of all mentions)] | 33 | 66 | 0\n",
      "$MU | [3 mentions (<1% of all mentions)] | 33 | 33 | 33\n",
      "$ET | [3 mentions (<1% of all mentions)] | 33 | 66 | 0\n",
      "$GME | [3 mentions (<1% of all mentions)] | 66 | 0 | 33\n",
      "$KGC | [3 mentions (<1% of all mentions)] | 33 | 66 | 0\n",
      "$KMX | [2 mentions (<1% of all mentions)] | 100 | 0 | 0\n",
      "$SPCE | [2 mentions (<1% of all mentions)] | 50 | 50 | 0\n",
      "$AAPL | [2 mentions (<1% of all mentions)] | 100 | 0 | 0\n",
      "$F | [2 mentions (<1% of all mentions)] | 50 | 0 | 50\n",
      "$DNUT | [2 mentions (<1% of all mentions)] | 50 | 0 | 50\n",
      "$SCR | [2 mentions (<1% of all mentions)] | 0 | 100 | 0\n",
      "$BGS | [2 mentions (<1% of all mentions)] | 50 | 50 | 0\n",
      "$OCGN | [2 mentions (<1% of all mentions)] | 50 | 50 | 0\n",
      "$TELL | [2 mentions (<1% of all mentions)] | 100 | 0 | 0\n",
      "$MSNT | [1 mention (<1% of all mentions)] | 100 | 0 | 0\n",
      "\n",
      "Version Alpha - Developed April 2021, Updated May 2021 - Aidan Slovinski.\n"
     ]
    }
   ],
   "source": [
    "#VERSION 1.3 (new section)\n",
    "import re\n",
    "import sys\n",
    "import praw\n",
    "import time\n",
    "import json\n",
    "import pprint\n",
    "import operator\n",
    "import datetime\n",
    "from praw.models import MoreComments\n",
    "#from iexfinance import Stock as IEXStock\n",
    "from iexfinance.stocks import Stock as IEXStock\n",
    "import os\n",
    "# to add the path for Python to search for files to use the edited version of vader\n",
    "sys.path.insert(0, 'vaderSentiment/vaderSentiment')\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "#analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#file_path = 'HistoricalHERALD.txt'\n",
    "#writes the output to the archive file -- disabled rn\n",
    "\n",
    "def extract_ticker(body, start_index):\n",
    "   #identifies ticker\n",
    "   count  = 0\n",
    "   ticker = \"\"\n",
    "\n",
    "   for char in body[start_index:]:\n",
    "      # if it should return\n",
    "      if not char.isalpha():\n",
    "         # if there aren't any letters following the $\n",
    "         if (count == 0):\n",
    "            return None\n",
    "\n",
    "         return ticker.upper()\n",
    "      else:\n",
    "         ticker += char\n",
    "         count += 1\n",
    "\n",
    "   return ticker.upper()\n",
    "\n",
    "def parse_section(ticker_dict, body):\n",
    "   #Parses the body of each comment and reply\n",
    "   blacklist_words = [\n",
    "      \"YOLO\", \"TOS\", \"CEO\", \"CFO\", \"CTO\", \"DD\", \"BTFD\", \"WSB\", \"OK\", \"RH\",\n",
    "      \"KYS\", \"FD\", \"TYS\", \"US\", \"USA\", \"IT\", \"ATH\", \"RIP\", \"BMW\", \"GDP\",\n",
    "      \"OTM\", \"ATM\", \"ITM\", \"IMO\", \"LOL\", \"DOJ\", \"BE\", \"PR\", \"PC\", \"ICE\",\n",
    "      \"TYS\", \"ISIS\", \"PRAY\", \"PT\", \"FBI\", \"SEC\", \"GOD\", \"NOT\", \"POS\", \"COD\",\n",
    "      \"AYYMD\", \"FOMO\", \"TL;DR\", \"EDIT\", \"STILL\", \"LGMA\", \"WTF\", \"RAW\", \"PM\",\n",
    "      \"LMAO\", \"LMFAO\", \"ROFL\", \"EZ\", \"RED\", \"BEZOS\", \"TICK\", \"IS\", \"DOW\"\n",
    "      \"AM\", \"PM\", \"LPT\", \"GOAT\", \"FL\", \"CA\", \"IL\", \"PDFUA\", \"MACD\", \"HQ\",\n",
    "      \"OP\", \"DJIA\", \"PS\", \"AH\", \"TL\", \"DR\", \"JAN\", \"FEB\", \"JUL\", \"AUG\",\n",
    "      \"SEP\", \"SEPT\", \"OCT\", \"NOV\", \"DEC\", \"FDA\", \"IV\", \"ER\", \"IPO\", \"RISE\"\n",
    "      \"IPA\", \"URL\", \"MILF\", \"BUT\", \"SSN\", \"FIFA\", \"USD\", \"CPU\", \"AT\",\n",
    "      \"GG\", \"ELON\", \"CUM\", \"ROPE\", \"BBAGHOLDERS\", \"MILK\",\"ASS\", \"DILDO\",\n",
    "   ]\n",
    "\n",
    "   if '$' in body:\n",
    "      index = body.find('$') + 1\n",
    "      word = extract_ticker(body, index)\n",
    "      \n",
    "      if word and word not in blacklist_words:\n",
    "         try:\n",
    "               if word in ticker_dict:\n",
    "                  ticker_dict[word].count += 1\n",
    "                  ticker_dict[word].bodies.append(body)\n",
    "                  price = IEXStock(word).get_price()\n",
    "               else:\n",
    "                  ticker_dict[word] = Ticker(word)\n",
    "                  ticker_dict[word].count = 1\n",
    "                  ticker_dict[word].bodies.append(body)\n",
    "         except:\n",
    "            pass\n",
    "   \n",
    "   # checks for non-$ formatted comments, splits every body into list of words\n",
    "   word_list = re.sub(\"[^\\w]\", \" \",  body).split()\n",
    "   for count, word in enumerate(word_list):\n",
    "      # initial screening of words\n",
    "      if word.isupper() and len(word) != 1 and (word.upper() not in blacklist_words) and len(word) <= 5 and word.isalpha():\n",
    "         # sends request to IEX API to determine whether the current word is a valid ticker\n",
    "         # if it isn't, it'll return an error and therefore continue on to the next word\n",
    "         try:\n",
    "            # special case for $TEST\n",
    "            if word != \"TEST\":\n",
    "               price = IEXStock(word).get_price()\n",
    "         except:\n",
    "            continue\n",
    "      \n",
    "         if word in ticker_dict:\n",
    "            ticker_dict[word].count += 1\n",
    "            ticker_dict[word].bodies.append(body)\n",
    "         else:\n",
    "            ticker_dict[word] = Ticker(word)\n",
    "            ticker_dict[word].count = 1\n",
    "            ticker_dict[word].bodies.append(body)\n",
    "\n",
    "   return ticker_dict\n",
    "\n",
    "def get_url(key, value, total_count):\n",
    "   # determine whether to use plural or singular\n",
    "   mention = (\"mentions\", \"mention\") [value == 1]\n",
    "   if int(value / total_count * 100) == 0:\n",
    "         perc_mentions = \"<1\"\n",
    "   else:\n",
    "         perc_mentions = int(value / total_count * 100)\n",
    "   # special case for $ROPE\n",
    "   if key == \"ROPE\":\n",
    "      return \"${0} | [{1} {2} ({3}% of all mentions)](https://www.homedepot.com/b/Hardware-Chains-Ropes-Rope/N-5yc1vZc2gr)\".format(key, value, mention, perc_mentions)\n",
    "   else:\n",
    "      return \"${0} | [{1} {2} ({3}% of all mentions)]\".format(key, value, mention, perc_mentions)\n",
    "\n",
    "def get_date():\n",
    "   now = datetime.datetime.now()\n",
    "   return now.strftime(\"%b %d, %Y\")\n",
    "\n",
    "def setup(sub):\n",
    "   if sub == \"\":\n",
    "      sub = \"wallstreetbets\"\n",
    "\n",
    "   #with open(\"config.json\") as json_data_file:\n",
    "    #  data = json.load(json_data_file)\n",
    "    \n",
    "   # create a reddit instance\n",
    "   reddit = praw.Reddit(client_id = \"cENOq22q9m2j0Q\",\n",
    "  client_secret = \"in-o3pyDTFONNqAXYPQjPd7en13zcQ\",\n",
    "  user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\")\n",
    "   # create an instance of the subreddit\n",
    "   subreddit = reddit.subreddit(sub)\n",
    "   return subreddit\n",
    "\n",
    "\n",
    "def run(mode, sub, num_submissions):\n",
    "   ticker_dict = {}\n",
    "   text = \"\"\n",
    "   total_count = 0\n",
    "   within24_hrs = False\n",
    "\n",
    "   subreddit = setup(sub)\n",
    "   new_posts = subreddit.new(limit=num_submissions)\n",
    "\n",
    "   for count, post in enumerate(new_posts):\n",
    "      # if we have not already viewed this post thread\n",
    "      if not post.clicked:\n",
    "         # parse the post's title's text\n",
    "         ticker_dict = parse_section(ticker_dict, post.title)\n",
    "\n",
    "         # to determine whether it has gone through all posts in the past 24 hours\n",
    "         if \"Daily Discussion Thread - \" in post.title:\n",
    "            if not within24_hrs:\n",
    "               within24_hrs = True\n",
    "            else:\n",
    "               print(\"\\nTotal posts searched: \" + str(count) + \"\\nTotal ticker mentions: \" + str(total_count))\n",
    "               break\n",
    "         \n",
    "         # search through all comments and replies to comments\n",
    "         comments = post.comments\n",
    "         for comment in comments:\n",
    "            # without this, would throw AttributeError since the instance in this represents the \"load more comments\" option\n",
    "            if isinstance(comment, MoreComments):\n",
    "               continue\n",
    "            ticker_dict = parse_section(ticker_dict, comment.body)\n",
    "\n",
    "            # iterate through the comment's replies\n",
    "            replies = comment.replies\n",
    "            for rep in replies:\n",
    "               # without this, would throw AttributeError since the instance in this represents the \"load more comments\" option\n",
    "               if isinstance(rep, MoreComments):\n",
    "                  continue\n",
    "               ticker_dict = parse_section(ticker_dict, rep.body)\n",
    "         \n",
    "         # update the progress count\n",
    "         sys.stdout.write(\"\\rProgress: {0} / {1} posts\".format(count + 1, num_submissions))\n",
    "         sys.stdout.flush()\n",
    "\n",
    "   text = \"A BEQUANT.ORG Model: The top ten stocks discussed on /r/wallstreetbets along with NLP analysis:\"\n",
    "   text += \"\\n\\nTicker | Mentions | Bullish (%) | Neutral (%) | Bearish (%)\\n:- | :- | :- | :- | :-\"\n",
    "\n",
    "   total_mentions = 0\n",
    "   ticker_list = []\n",
    "   for key in ticker_dict:\n",
    "      # print(key, ticker_dict[key].count)\n",
    "      total_mentions += ticker_dict[key].count\n",
    "      ticker_list.append(ticker_dict[key])\n",
    "\n",
    "   ticker_list = sorted(ticker_list, key=operator.attrgetter(\"count\"), reverse=True)\n",
    "\n",
    "   for ticker in ticker_list:\n",
    "      Ticker.analyze_sentiment(ticker)\n",
    "\n",
    "   # will break as soon as it hits a ticker with fewer than 5 mentions\n",
    "   for count, ticker in enumerate(ticker_list):\n",
    "      if count == 40:\n",
    "         break\n",
    "      \n",
    "      url = get_url(ticker.ticker, ticker.count, total_mentions)\n",
    "      # setting up formatting for table\n",
    "      text += \"\\n{} | {} | {} | {}\".format(url, ticker.bullish, ticker.neutral, ticker.bearish)\n",
    "      #sys.stdout = open(\"HistoricalHERALD.txt\", 'a')\n",
    "   text += \"\\n\\nVersion Alpha - Developed April 2021, Updated May 2021 - Aidan Slovinski.\"\n",
    "\n",
    "  
    "\n",
    "class Ticker:\n",
    "   def __init__(self, ticker):\n",
    "      self.ticker = ticker\n",
    "      self.count = 0\n",
    "      self.bodies = []\n",
    "      self.pos_count = 0\n",
    "      self.neg_count = 0\n",
    "      self.bullish = 0\n",
    "      self.bearish = 0\n",
    "      self.neutral = 0\n",
    "      self.sentiment = 0 # 0 is neutral\n",
    "\n",
    "   def analyze_sentiment(self):\n",
    "      analyzer = SentimentIntensityAnalyzer()\n",
    "      neutral_count = 0\n",
    "      for text in self.bodies:\n",
    "         sentiment = analyzer.polarity_scores(text)\n",
    "         if (sentiment[\"compound\"] > .005) or (sentiment[\"pos\"] > abs(sentiment[\"neg\"])):\n",
    "            self.pos_count += 1\n",
    "         elif (sentiment[\"compound\"] < -.005) or (abs(sentiment[\"neg\"]) > sentiment[\"pos\"]):\n",
    "            self.neg_count += 1\n",
    "         else:\n",
    "            neutral_count += 1\n",
    "\n",
    "      self.bullish = int(self.pos_count / len(self.bodies) * 100)\n",
    "      self.bearish = int(self.neg_count / len(self.bodies) * 100)\n",
    "      self.neutral = int(neutral_count / len(self.bodies) * 100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   # USAGE: wsbtickerbot.py [ subreddit ] [ num_submissions ]\n",
    "   mode = 1\n",
    "   num_submissions = 295\n",
    "   sub = \"wallstreetbets\"\n",
    "\n",
    "   run(mode, sub, num_submissions)\n",
    "    #new post analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
